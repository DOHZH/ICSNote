# 优化编译器的能力与局限性
1. 编译器经常利用一些机会简化表达式，降低计算的执行次数
2. 大多数编译器允许用户决定优化级别
   1. GCC通过`-Og`调用GCC的基本优化
   2. `-o1`和`-o2`是更高级别的优化，但是会造成程序规模的增加或者调试难度的增加
   3. 有时高级别优化可能反而会导致程序性能损失
3. 内存别名使用导致的优化阻碍<br>![](./pic/chapter5/01.PNG)
   1. 在这两段代码中，函数twiddle2 的效率更高。
      1. twiddle2：`*xp += 2 * *yp;`这句执行了一次读取\*yp，一次读取\*xp，然后将计算的结果写入\*xp。一共执行3次读写操作
      2. twiddle1：`*xp += *yp;`每次执行都会执行一次读取\*yp，一次读取\*xp，然后将计算的结果写入\*xp。一共两句，所以共执行6次读写操作
   2. 照理说，如果我们把代码写成twiddle1形式，编译器为了效率应该帮我们优化成twiddle2这种形式。但是现实中编译器不会这样做
      1. 考虑xp=yp的情况：
      ```
      //twiddle1:
      *xp += *xp;/2 * *xp/
      *xp += *xp;/2 * (2 * *xp)/
      
      //twiddle2:
      *xp += 2 * *xp; /*xp + 2*xp/ 
      ```
      2. 此时我们发现twiddle2和twiddle产生的结果不一样，所以编译器不会使用优化
      3. 内存别名使用：这种两个指针可能指向同一个内存的情况叫做内存别名使用
      4. 对于执行安全优化的编译器来说，编译器在面对内存别名使用的情况时不会进行优化
   3. 内存指向未知带来的优化阻碍
      1. 有代码：<br>![](./pic/chapter5/02.PNG)
      2. 因为我们起初明没有给出指针p与指针q的初始化代码。如果p和q指向的地址不同，那么t1=3000。但是如果两个指针指向的地址相同，那么*p=x会让这个地址最后对应的值为1000，导致t1=1000
      3. 因此，如果编译器如果无法确定两个指针的地址是否相异，那么他们会假设所有情况都会发生，限制了可能的优化策略
4. 函数调用导致的优化阻碍：
   1. 代码：<br>![](./pic/chapter5/03.PNG)
   2. 这个代码的func1和func2看似相同，但是func2却不能作为func1的优化。因为如果有<br>![](./pic/chapter5/04.PNG)<br>此时func1返回6（0+1+2+3=6），func2返回0（4*0=0）
   3. 大多数编译器会假设最糟的情况，因此保持原有调用不变而不会对其优化
   4. 关于`x++`和`++x`：“x++”是先把值参与运算以后，自身再进行加一的，而“++x”是自身先加一再参与运算。即如果y=x++，那么y=x，然后x再对自己执行+1；y=++x，是先对x+1，然后再赋值给y

# 程序性能的表示
1. 度量标准：每元素的周期数（CPE）
   1. 对于一个程序，如果我们记录该程序的数据规模以及对应的运行所需的时钟周期，并通过最小二乘法来拟合这些点，我们将得到形如y = a + bx 的表达式，其中y 是时钟周期，x 是数据规模。
   2. 当数据规模较大时，运行时间就主要由线性因子b 来决定。这时候，我们将b 作为度量程序性能的标准，称为**每元素的周期数**
2. 处理器活动由时钟控制，时钟控制某个频率的规律信号，用千兆赫兹（GHz）表示
   1. 千兆赫兹即十亿周期/秒
   2. 4GHz处理器表示处理器时钟运行频率为每秒$4 \times 10^9$
   3. 我们以纳秒（$10^{-9}$秒）或皮秒（$10^{-12}$秒）表示处理器的时钟周期。比如4GHz的1次时钟周期为0.25纳秒或者250皮秒


## 如何优化
## 1. 程序示例
1. 定义一个向量<br>:![](./pic/chapter5/05.PNG)<br>![](./pic/chapter5/06.PNG)<br>data_t为基本元素的数据类型：<br>![](./pic/chapter5/07.PNG)
2. 对向量求和或者求积：<br>![](./pic/chapter5/08.PNG)
   1. OP：OP是一个运算符，具体是求积还是求和取决于我们下面的定义：
        ```
        #define IDENT 0
        #define OP +

        #define IDENT 1
        #define OP *
        ```
   2. get_vec_element：获取第i个元素的值，并把结果保存在val中
   3. 运行效率对比：<br>![](./pic/chapter5/08.PNG)<br>我们发现O1的优化方法可以显著提高程序性能

## 2. 消除循环的低效率：减少重复计算
1. 代码移动：
   1. 主要针对要在循环中执行多次但是计算结果不会改变的计算，因此我们把计算移动到循环之外进行计算
   2. 编译器会试着进行代码移动，但是出于安全性考虑，最好还是由程序员进行手动改进
2. 例子：<br>![](./pic/chapter5/10.PNG)<br>![](./pic/chapter5/11.PNG)
   1. 我们在lower2中就把在lower1中反复计算的strlen()移除了循环，大大提升了程序的运算速度
   2. str(len)是依靠循环测验字符串长度，所以lower1的复杂度是$n^2$。但是lower2因为提前计算好的，程序复杂度只有$n$

## 3. 减少过程调用
1. 构成调用会带来开销，并且妨碍程序优化
2. 这个例子中，每次循环都会调用函数get_vec_element<br>![](./pic/chapter5/12.PNG)<br>![](./pic/chapter5/13.PNG)
   1. get_vec_element每次都会获取下一个向量元素，同时检查i是否超出循环边界。尽管这是一个很好的安全意识，但是combine2明显没有越界引用，那么这种检查就是多余的
   2. 我们使用如下的优化，即减少循环中的函数调用：<br>![](./pic/chapter5/14.PNG)<br>我们使用get_vec_start直接获取数组指针，然后直接在循环中访问数组
   3. combine3中的[OP](#1-程序示例)在前面给出了定义，他会根据输入值得不同决定这是加或乘
   4. 实际上，combine3效率还弱于combine2，这是因为其他部分出现了问题，我们将在[消除不必要的内存引用](#4-消除不必要的内存引用)进行解释。但是这种减少调用的习惯是必要的

## 4. 消除不必要的内存引用
1. combine3的分析：<br>![](./pic/chapter5/15.PNG)
   1. 这里我们发现在运算时，先要吧dest的值从rdx对应的地址位置取出，存储在xmm0中。在计算完毕后，再把xmm0计算完的\*dest的值存回rbx。这样的反复读写是浪费效率的
2. combine4：避免了反复读写：<br>![](./pic/chapter5/16.PNG)
   1. 这种改写避免了对指针寄存器的反复操作。通过引入一个临时变量acc记录每次的计算值。因为acc是一个非指针变量，因此计算时会永远存在xmm0中，全部计算完成后再放入\*dest
   2. 编译器很难将combine3优化成combine4，因为存在**内存别名**的情况，导致两个函数会导致不同行为：<br>![](./pic/chapter5/17.PNG)
      1. IDENT的定义：<br>![](./pic/chapter5/18.PNG)<br>这里我们假定IDENT=1,OP为乘号
      2. combine3因为是利用指针操作，并且\*dest就是v[2]，所以一开始\*dest=IDENT会改变v最后的值。并且每次改变\*dest的值时我们都会改动v[2]。当i=2时，我们执行的不是6\*5，而是$*dest \times (*dest)=6\times 6 = 36$
      3. 而对于combine4，我们对中间变量acc赋值IDENT，而不是对dest操作，所以我们的向量v并没有发生任何变化。combine4这种函数明显更符合我们对于函数的要求，但是编译器不会分辨他和combine3的区别，只会认为这两个都一样好

# 现代处理器的运作
1. 实际处理器，会同时对多条指令求值，这个叫指令级并行
2. 当一系列必须按照严格顺序执行（即必须这条指令执行完才能执行下一个指令），就会遇到延迟界限。
3. 延迟界限是阻止处理器进行指令级并行的主要障碍
4. 吞吐量界限刻画了处理器功能单元的原始计算能力，这个界限是程序性能的终极限制
## 1. 处理器整体情况
1. 超标量：即处理器可以在每个时钟周期乱序执行多个操作（即指令执行顺序不必与机器级程序中顺序一致）
2. 乱序处理器往往比in-order的流水线比更大且更复杂，但是有更好的并行能力
3. 乱序处理器主要分为两个部分：指令控制单元（ICU）和执行单元（EU）
   1. ICU：从内存中读取指令序列，并根据指令序列生成一组针对程序数据的基本操作
      1. ICU从指令高速缓存读取指令
      2. 指令高速缓存：一个特殊的高速存储器，保存最近访问的指令
      3. ICU通常在指令执行很早之前就取指，以便发给EU。但是遇到分支时，需要进行分支预测
      4. 分支预测：处理器猜测会选择哪一个分支以及其目标地址
      5. 投机执行：处理器会开始取出位于它预测的分支，并跳转到指定位置读取并让EU执行。如果预测错误，处理器会将状态重新设置到分支点状态，并重新计算正确分支
      6. 指令译码：接收实际的程序指令，并将其转化成一组基本操作。比如x86会将一个复杂的运算译码成多个简单操作。译码采用队列处理指令，先进先出
      7. 退役单元：记录正在进行的处理，确保他们遵循机器级程序的顺序。
         1. 寄存器文件是退役单元的一部分，因为退役单元控制这些寄存器的更新
         2. 指令译码时会采用队列，先进先出。一条指令一旦译码完成，如果不存在分支预测错误则该指令退役，该指令的操作会被执行。如果预测错误，该执行会被退役单元清空
   2. EU：执行从ICU生成的操作
      1. EU每个时钟周期会接收多个操作，这些操作被分派到一组功能单元中执行实际的操作。每个功能单元都有自己专门的处理类型
      2. 读写内存：由加载和存储单元实现。它通过数据高速缓存来访问内存。在读写数据的过程中，有一个加法器会协助单元完成地址计算
      3. 投机执行技术会将计算出来的值发送给EU，让EU判断正确与否。如果错误，分支单元会接收EU的信号后把告知ICU分支预测错误，并指出正确分支
      4. 各执行单元可以直接将结果发送给彼此（在图中就是“操作结果”那条横线）
   
   3. 流程图：<br>![](./pic/chapter5/19.PNG)
   4. 每个单元执行的功能并不是单一的：<br>![](./pic/chapter5/20.PNG)
   5. 寄存器重命名：保证了即使在处理器确定了分支结果之后才能更新寄存器也可以预测着执行操作的整个序列
      1. 当一条更新寄存器r的指令译码时，记录映射(r,t)，t为此时r的标记。这个映射被记录在一张表中
      2. 在操作寄存器r时，发送给执行单元的操作会包含t作为操作数源
      3. 指令执行完成，产生一个新映射结果（v,t），指明操作数源t会产生结果v。
      4. 有了这个映射，处理器会把所有以t作为操作数源的操作的结果都处理为v
      5. 这种操作可以让相同操作不必再读写寄存器，加快了操作，并且保证了不会因为乱序导致操作结果出现错误

## 2. 功能单元的性能
1. 